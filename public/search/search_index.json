{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Nextflow Patterns This page collects some recurring implementation patterns used in Nextflow applications. Feel free to contribute by opening a pull request in the GitHub repository .","title":"Home"},{"location":"#nextflow-patterns","text":"This page collects some recurring implementation patterns used in Nextflow applications. Feel free to contribute by opening a pull request in the GitHub repository .","title":"Nextflow Patterns"},{"location":"channel-duplication/","text":"Problem You need to you use the same channel as input in two or more processes. Solution In DSL2, you can just do it! The into operator is no longer needed. Code process foo { input: path x script: \"\"\" echo your_command --input $x \"\"\" } process bar { input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { input_ch = Channel.fromPath(\"$baseDir/data/prots/*_?.fa\") foo(input_ch) bar(input_ch) } Run it Use the the following command to execute the example: nextflow run patterns/channel-duplication.nf","title":"Channel duplication"},{"location":"channel-duplication/#problem","text":"You need to you use the same channel as input in two or more processes.","title":"Problem"},{"location":"channel-duplication/#solution","text":"In DSL2, you can just do it! The into operator is no longer needed.","title":"Solution"},{"location":"channel-duplication/#code","text":"process foo { input: path x script: \"\"\" echo your_command --input $x \"\"\" } process bar { input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { input_ch = Channel.fromPath(\"$baseDir/data/prots/*_?.fa\") foo(input_ch) bar(input_ch) }","title":"Code"},{"location":"channel-duplication/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/channel-duplication.nf","title":"Run it"},{"location":"collect-into-file/","text":"Problem You need to concatenate into a single file all output files produced by an upstream process. Solution Use the collectFile operator to merge all the output files into a single file. Code process foo { input: path x output: path 'file.fq' script: \"\"\" < $x zcat > file.fq \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\ | foo \\ | collectFile \\ | view } Run it Use the the following command to execute the example: nextflow run patterns/collect-into-file.nf","title":"Collect outputs into a file"},{"location":"collect-into-file/#problem","text":"You need to concatenate into a single file all output files produced by an upstream process.","title":"Problem"},{"location":"collect-into-file/#solution","text":"Use the collectFile operator to merge all the output files into a single file.","title":"Solution"},{"location":"collect-into-file/#code","text":"process foo { input: path x output: path 'file.fq' script: \"\"\" < $x zcat > file.fq \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\ | foo \\ | collectFile \\ | view }","title":"Code"},{"location":"collect-into-file/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/collect-into-file.nf","title":"Run it"},{"location":"conditional-process/","text":"Problem One of two different tasks should be executed based on some condition, and a third task should process the results of the selected task. Solution Simply execute either process using if/else statements on the condition. Define a channel, e.g. omega_ch , which emits the output of the selected process in each case. Then, execute the third process with this output channel. Or, use a ternary expression and a pipe to keep things short and sweet. Code params.flag = false process foo { output: path 'x.txt' script: ''' echo foo > x.txt ''' } process bar { output: path 'x.txt' script: ''' echo bar > x.txt ''' } process omega { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { // the long way if ( params.flag ) { bar() omega_ch = bar.out } else { foo() omega_ch = foo.out } omega(omega_ch) // the short way (params.flag ? bar : foo) | omega } Run it Use the the following command to execute the example: nextflow run patterns/conditional-process.nf The processes foo and omega are executed. Run the same command with the --flag command line option. nextflow run patterns/conditional-process.nf --flag This time the processes bar and omega are executed. Alternative solution Create an input channel for each process that is either populated with data or an empty channel. Each process will execute only if its input channel has data. Then use the mix operator to create a new channel that emits the outputs produced by the two processes, and use it as the input for the third process. Code params.flag = false process foo { input: val x output: path 'x.txt' script: \"\"\" echo $x > x.txt \"\"\" } process bar { input: val(b) output: path 'x.txt' script: \"\"\" echo $b > x.txt \"\"\" } process omega { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { (foo_ch, bar_ch) = params.flag ? [ Channel.empty(), Channel.from(1,2,3) ] : [ Channel.from(4,5,6), Channel.empty() ] foo(foo_ch) bar(bar_ch) foo.out | mix(bar.out) | omega } Run it nextflow run patterns/conditional-process2.nf","title":"Conditional process executions"},{"location":"conditional-process/#problem","text":"One of two different tasks should be executed based on some condition, and a third task should process the results of the selected task.","title":"Problem"},{"location":"conditional-process/#solution","text":"Simply execute either process using if/else statements on the condition. Define a channel, e.g. omega_ch , which emits the output of the selected process in each case. Then, execute the third process with this output channel. Or, use a ternary expression and a pipe to keep things short and sweet.","title":"Solution"},{"location":"conditional-process/#code","text":"params.flag = false process foo { output: path 'x.txt' script: ''' echo foo > x.txt ''' } process bar { output: path 'x.txt' script: ''' echo bar > x.txt ''' } process omega { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { // the long way if ( params.flag ) { bar() omega_ch = bar.out } else { foo() omega_ch = foo.out } omega(omega_ch) // the short way (params.flag ? bar : foo) | omega }","title":"Code"},{"location":"conditional-process/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/conditional-process.nf The processes foo and omega are executed. Run the same command with the --flag command line option. nextflow run patterns/conditional-process.nf --flag This time the processes bar and omega are executed.","title":"Run it"},{"location":"conditional-process/#alternative-solution","text":"Create an input channel for each process that is either populated with data or an empty channel. Each process will execute only if its input channel has data. Then use the mix operator to create a new channel that emits the outputs produced by the two processes, and use it as the input for the third process.","title":"Alternative solution"},{"location":"conditional-process/#code_1","text":"params.flag = false process foo { input: val x output: path 'x.txt' script: \"\"\" echo $x > x.txt \"\"\" } process bar { input: val(b) output: path 'x.txt' script: \"\"\" echo $b > x.txt \"\"\" } process omega { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { (foo_ch, bar_ch) = params.flag ? [ Channel.empty(), Channel.from(1,2,3) ] : [ Channel.from(4,5,6), Channel.empty() ] foo(foo_ch) bar(bar_ch) foo.out | mix(bar.out) | omega }","title":"Code"},{"location":"conditional-process/#run-it_1","text":"nextflow run patterns/conditional-process2.nf","title":"Run it"},{"location":"conditional-resources/","text":"Problem A task in your workflow needs to use some amount of computing resources (e.g. memory) that depends on the size or the name of one or more input files. Solution Declare the resource requirements ( memory , cpus , etc.) in a dynamic manner using a closure. The closure computes the required amount of resources using the file attributes (e.g. size ) of the inputs declared in the process definition. Code process foo { memory { reads.size() < 70.KB ? 1.GB : 5.GB } input: path reads \"\"\" echo your_command_here --in ${reads} --mem=${task.memory.giga} \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists:true) \\ | foo } Run it nextflow run patterns/conditional-resources.nf","title":"Conditional process resources"},{"location":"conditional-resources/#problem","text":"A task in your workflow needs to use some amount of computing resources (e.g. memory) that depends on the size or the name of one or more input files.","title":"Problem"},{"location":"conditional-resources/#solution","text":"Declare the resource requirements ( memory , cpus , etc.) in a dynamic manner using a closure. The closure computes the required amount of resources using the file attributes (e.g. size ) of the inputs declared in the process definition.","title":"Solution"},{"location":"conditional-resources/#code","text":"process foo { memory { reads.size() < 70.KB ? 1.GB : 5.GB } input: path reads \"\"\" echo your_command_here --in ${reads} --mem=${task.memory.giga} \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists:true) \\ | foo }","title":"Code"},{"location":"conditional-resources/#run-it","text":"nextflow run patterns/conditional-resources.nf","title":"Run it"},{"location":"feedback-loop/","text":"Problem You need to repeat a process or workflow multiple times, using the output from the previous iteration as the input to the next iteration. Solution Warning This feature is experimental and may change in the future. Use the recurse method on a process or workflow to execute it iteratively. In order to use this feature, the process or workflow must have identical input and output definitions, and any initial values must be Groovy values or value channels -- queue channels are not supported (yet). You can use the times operator to perform a fixed number of iterations, or the until operator to iterate until some condition is satisfied. Code For an iterative process: nextflow.preview.recursion=true params.data = \"$baseDir/data/hello.txt\" process foo { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} was here\" >> result.txt \"\"\" } workflow { // perform a fixed number of iterations foo .recurse(file(params.data)) .times(10) // iterate until some condition is satisfied foo .recurse(file(params.data)) .until { it -> it.size() > 100 } foo .out .view(it -> it.text) } For an iterative workflow: nextflow.preview.recursion=true params.input = \"$baseDir/data/hello.txt\" process tick { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} : tick\" >> result.txt \"\"\" } process tock { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} : tock\" >> result.txt \"\"\" } workflow clock { take: infile main: infile | tick | tock emit: tock.out } workflow { clock .recurse(file(params.input)) .until { it -> it.size() > 100 } clock .out .view(it -> it.text) } Run it Use the the following command to execute the example: # iterative process nextflow run patterns/feedback-loop-process.nf # iterative workflow nextflow run patterns/feedback-loop-workflow.nf","title":"Feedback loop"},{"location":"feedback-loop/#problem","text":"You need to repeat a process or workflow multiple times, using the output from the previous iteration as the input to the next iteration.","title":"Problem"},{"location":"feedback-loop/#solution","text":"Warning This feature is experimental and may change in the future. Use the recurse method on a process or workflow to execute it iteratively. In order to use this feature, the process or workflow must have identical input and output definitions, and any initial values must be Groovy values or value channels -- queue channels are not supported (yet). You can use the times operator to perform a fixed number of iterations, or the until operator to iterate until some condition is satisfied.","title":"Solution"},{"location":"feedback-loop/#code","text":"For an iterative process: nextflow.preview.recursion=true params.data = \"$baseDir/data/hello.txt\" process foo { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} was here\" >> result.txt \"\"\" } workflow { // perform a fixed number of iterations foo .recurse(file(params.data)) .times(10) // iterate until some condition is satisfied foo .recurse(file(params.data)) .until { it -> it.size() > 100 } foo .out .view(it -> it.text) } For an iterative workflow: nextflow.preview.recursion=true params.input = \"$baseDir/data/hello.txt\" process tick { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} : tick\" >> result.txt \"\"\" } process tock { input: path 'input.txt' output: path 'result.txt' script: \"\"\" cat input.txt > result.txt echo \"Task ${task.index} : tock\" >> result.txt \"\"\" } workflow clock { take: infile main: infile | tick | tock emit: tock.out } workflow { clock .recurse(file(params.input)) .until { it -> it.size() > 100 } clock .out .view(it -> it.text) }","title":"Code"},{"location":"feedback-loop/#run-it","text":"Use the the following command to execute the example: # iterative process nextflow run patterns/feedback-loop-process.nf # iterative workflow nextflow run patterns/feedback-loop-workflow.nf","title":"Run it"},{"location":"ignore-failing-process/","text":"Problem A task is expected to fail in some cases. You want to ignore the failure and continue the execution of the remaining tasks in the workflow. Solution Use the process directive errorStrategy 'ignore' to ignore the error condition. Code process foo { errorStrategy 'ignore' script: ''' echo This is going to fail! exit 1 ''' } process bar { script: ''' echo OK ''' } workflow { foo() bar() } Run it Run the script with the following command: nextflow run patterns/ignore-failing-process.nf","title":"Ignore failing process"},{"location":"ignore-failing-process/#problem","text":"A task is expected to fail in some cases. You want to ignore the failure and continue the execution of the remaining tasks in the workflow.","title":"Problem"},{"location":"ignore-failing-process/#solution","text":"Use the process directive errorStrategy 'ignore' to ignore the error condition.","title":"Solution"},{"location":"ignore-failing-process/#code","text":"process foo { errorStrategy 'ignore' script: ''' echo This is going to fail! exit 1 ''' } process bar { script: ''' echo OK ''' } workflow { foo() bar() }","title":"Code"},{"location":"ignore-failing-process/#run-it","text":"Run the script with the following command: nextflow run patterns/ignore-failing-process.nf","title":"Run it"},{"location":"optional-input/","text":"Problem One or more processes have an optional input file. Solution Use a special file name to mark the absence of the file parameter. Code params.inputs = \"$baseDir/data/prots/*{1,2,3}.fa\" params.filter = 'NO_FILE' process foo { debug true input: path seq path opt script: def filter = opt.name != 'NO_FILE' ? \"--filter $opt\" : '' \"\"\" echo your_commad --input $seq $filter \"\"\" } workflow { prots_ch = Channel.fromPath(params.inputs, checkIfExists:true) opt_file = file(params.filter) foo(prots_ch, opt_file) } Run it Run the script with the following command: nextflow run patterns/optional-input.nf Run the same script providing an optional file input: nextflow run patterns/optional-input.nf --filter foo.txt","title":"Optional input"},{"location":"optional-input/#problem","text":"One or more processes have an optional input file.","title":"Problem"},{"location":"optional-input/#solution","text":"Use a special file name to mark the absence of the file parameter.","title":"Solution"},{"location":"optional-input/#code","text":"params.inputs = \"$baseDir/data/prots/*{1,2,3}.fa\" params.filter = 'NO_FILE' process foo { debug true input: path seq path opt script: def filter = opt.name != 'NO_FILE' ? \"--filter $opt\" : '' \"\"\" echo your_commad --input $seq $filter \"\"\" } workflow { prots_ch = Channel.fromPath(params.inputs, checkIfExists:true) opt_file = file(params.filter) foo(prots_ch, opt_file) }","title":"Code"},{"location":"optional-input/#run-it","text":"Run the script with the following command: nextflow run patterns/optional-input.nf Run the same script providing an optional file input: nextflow run patterns/optional-input.nf --filter foo.txt","title":"Run it"},{"location":"optional-output/","text":"Problem A task in your workflow is expected to not create an output file in some circumstances. Solution Declare such output as an optional file. Code process foo { output: path 'foo.txt', optional: true script: ''' your_command ''' } Run it Use the the following command to execute the example: nextflow run patterns/optional-output.nf","title":"Optional output"},{"location":"optional-output/#problem","text":"A task in your workflow is expected to not create an output file in some circumstances.","title":"Problem"},{"location":"optional-output/#solution","text":"Declare such output as an optional file.","title":"Solution"},{"location":"optional-output/#code","text":"process foo { output: path 'foo.txt', optional: true script: ''' your_command ''' }","title":"Code"},{"location":"optional-output/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/optional-output.nf","title":"Run it"},{"location":"process-collect/","text":"Problem You need to process all the outputs of an upstream task altogether. Solution Use the collect operator to gather all the outputs produced by the upstream task and emit them as a single output. Then use the resulting channel as input for the downstream task. Code process foo { input: path x output: path 'file.fq' script: \"\"\" < $x zcat > file.fq \"\"\" } process bar { debug true input: path '*.fq' script: \"\"\" cat *.fq | head -n 50 \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\ | foo \\ | collect \\ | bar } Run it Use the the following command to execute the example: nextflow run patterns/process-collect.nf","title":"Process all outputs altogether"},{"location":"process-collect/#problem","text":"You need to process all the outputs of an upstream task altogether.","title":"Problem"},{"location":"process-collect/#solution","text":"Use the collect operator to gather all the outputs produced by the upstream task and emit them as a single output. Then use the resulting channel as input for the downstream task.","title":"Solution"},{"location":"process-collect/#code","text":"process foo { input: path x output: path 'file.fq' script: \"\"\" < $x zcat > file.fq \"\"\" } process bar { debug true input: path '*.fq' script: \"\"\" cat *.fq | head -n 50 \"\"\" } workflow { Channel.fromPath(\"$baseDir/data/reads/*_1.fq.gz\", checkIfExists: true) \\ | foo \\ | collect \\ | bar }","title":"Code"},{"location":"process-collect/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/process-collect.nf","title":"Run it"},{"location":"process-get-workdir/","text":"Problem A tool needs the explicit path of the current task work directory. Solution Use the $PWD Bash variable or the pwd command to retrieve the task working directory path. Note Make sure to escape the $ variable placeholder when the command script is enclosed in double quote characters. Example process foo { debug true script: \"\"\" echo foo task path: \\$PWD \"\"\" } process bar { debug true script: ''' echo bar task path: $PWD ''' } workflow { foo() bar() } Run it The command run the script with an empty channel: nextflow run patterns/process-get-workdir.nf Use the following command to provide the same script some input files, that prevents the process from being executed: nextflow run patterns/process-get-workdir.nf --inputs ../data/prots/ \\*","title":"Get process work directory"},{"location":"process-get-workdir/#problem","text":"A tool needs the explicit path of the current task work directory.","title":"Problem"},{"location":"process-get-workdir/#solution","text":"Use the $PWD Bash variable or the pwd command to retrieve the task working directory path. Note Make sure to escape the $ variable placeholder when the command script is enclosed in double quote characters.","title":"Solution"},{"location":"process-get-workdir/#example","text":"process foo { debug true script: \"\"\" echo foo task path: \\$PWD \"\"\" } process bar { debug true script: ''' echo bar task path: $PWD ''' } workflow { foo() bar() }","title":"Example"},{"location":"process-get-workdir/#run-it","text":"The command run the script with an empty channel: nextflow run patterns/process-get-workdir.nf Use the following command to provide the same script some input files, that prevents the process from being executed: nextflow run patterns/process-get-workdir.nf --inputs ../data/prots/ \\*","title":"Run it"},{"location":"process-into-groups/","text":"Problem You need to process in the same batch all files that have a matching key in the file name. Solution Use the map operator to associate each file with a key extracted from the file name. Then chain the resulting channel with the groupTuple operator to group together all files that have a matching key. Finally, use the resulting channel as input for the process. Code params.reads = \"$baseDir/data/reads/*\" process foo { debug true input: tuple val(key), file(samples) script: \"\"\" echo your_command --batch $key --input $samples \"\"\" } workflow { Channel.fromPath(params.reads, checkIfExists:true) \\ | map { file -> def key = file.name.toString().tokenize('_').get(0) return tuple(key, file) } \\ | groupTuple() \\ | foo } Run it nextflow run patterns/process-into-groups.nf","title":"Process outputs into groups"},{"location":"process-into-groups/#problem","text":"You need to process in the same batch all files that have a matching key in the file name.","title":"Problem"},{"location":"process-into-groups/#solution","text":"Use the map operator to associate each file with a key extracted from the file name. Then chain the resulting channel with the groupTuple operator to group together all files that have a matching key. Finally, use the resulting channel as input for the process.","title":"Solution"},{"location":"process-into-groups/#code","text":"params.reads = \"$baseDir/data/reads/*\" process foo { debug true input: tuple val(key), file(samples) script: \"\"\" echo your_command --batch $key --input $samples \"\"\" } workflow { Channel.fromPath(params.reads, checkIfExists:true) \\ | map { file -> def key = file.name.toString().tokenize('_').get(0) return tuple(key, file) } \\ | groupTuple() \\ | foo }","title":"Code"},{"location":"process-into-groups/#run-it","text":"nextflow run patterns/process-into-groups.nf","title":"Run it"},{"location":"process-per-csv-record/","text":"Problem You need to execute a task for each record in one or more CSV files. Solution Read the CSV file line-by-line using the splitCsv operator, then use the map operator to return a tuple with the required field for each line and convert any string path to a file path object using the file function. Finally, use the resulting channel as input for the process. Code Given the file index.csv with the following content: sampleId read1 read2 FC816RLABXX reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_1.fq.gz reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_2.fq.gz FC812MWABXX reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_1.fq.gz reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_2.fq.gz FC81DE8ABXX reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_1.fq.gz reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_2.fq.gz FC81DB5ABXX reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_1.fq.gz reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_2.fq.gz FC819P0ABXX reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_1.fq.gz reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_2.fq.gz This workflow parses the file and executes a process for each line: params.index = \"$baseDir/data/index.csv\" process foo { debug true input: tuple val(sampleId), file(read1), file(read2) script: \"\"\" echo your_command --sample $sampleId --reads $read1 $read2 \"\"\" } workflow { Channel.fromPath(params.index) \\ | splitCsv(header:true) \\ | map { row-> tuple(row.sampleId, file(row.read1), file(row.read2)) } \\ | foo } Note Relative paths are resolved by the file function against the execution directory. In practice, it is preferable to use absolute file paths. Run it Use the the following command to execute the example: nextflow run patterns/process-per-csv-record.nf","title":"Process per CSV record"},{"location":"process-per-csv-record/#problem","text":"You need to execute a task for each record in one or more CSV files.","title":"Problem"},{"location":"process-per-csv-record/#solution","text":"Read the CSV file line-by-line using the splitCsv operator, then use the map operator to return a tuple with the required field for each line and convert any string path to a file path object using the file function. Finally, use the resulting channel as input for the process.","title":"Solution"},{"location":"process-per-csv-record/#code","text":"Given the file index.csv with the following content: sampleId read1 read2 FC816RLABXX reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_1.fq.gz reads/110101_I315_FC816RLABXX_L1_HUMrutRGXDIAAPE_2.fq.gz FC812MWABXX reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_1.fq.gz reads/110105_I186_FC812MWABXX_L8_HUMrutRGVDIABPE_2.fq.gz FC81DE8ABXX reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_1.fq.gz reads/110121_I288_FC81DE8ABXX_L3_HUMrutRGXDIAAPE_2.fq.gz FC81DB5ABXX reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_1.fq.gz reads/110122_I329_FC81DB5ABXX_L6_HUMrutRGVDIAAPE_2.fq.gz FC819P0ABXX reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_1.fq.gz reads/110128_I481_FC819P0ABXX_L5_HUMrutRGWDIAAPE_2.fq.gz This workflow parses the file and executes a process for each line: params.index = \"$baseDir/data/index.csv\" process foo { debug true input: tuple val(sampleId), file(read1), file(read2) script: \"\"\" echo your_command --sample $sampleId --reads $read1 $read2 \"\"\" } workflow { Channel.fromPath(params.index) \\ | splitCsv(header:true) \\ | map { row-> tuple(row.sampleId, file(row.read1), file(row.read2)) } \\ | foo } Note Relative paths are resolved by the file function against the execution directory. In practice, it is preferable to use absolute file paths.","title":"Code"},{"location":"process-per-csv-record/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/process-per-csv-record.nf","title":"Run it"},{"location":"process-per-file-chunk/","text":"Problem You need to split one or more input files into chunks and execute a task for each of them. Solution Use the splitText operator to split a file into chunks of a given size. Then use the resulting channel as input for the process implementing your task. Warning Chunks are kept in memory by default. When splitting big files, specify the parameter file: true to save the chunks into files. See the documentation for details. Splitter for specific file formats are available, e.g. splitFasta and splitFastq . Code params.infile = \"$baseDir/data/poem.txt\" params.size = 5 process foo { debug true input: file x script: \"\"\" rev $x | rev \"\"\" } workflow { Channel.fromPath(params.infile) \\ | splitText(by: params.size) \\ | foo } Run it Use the the following command to execute the example: nextflow run patterns/process-per-file-chunk.nf","title":"Process per file chunk"},{"location":"process-per-file-chunk/#problem","text":"You need to split one or more input files into chunks and execute a task for each of them.","title":"Problem"},{"location":"process-per-file-chunk/#solution","text":"Use the splitText operator to split a file into chunks of a given size. Then use the resulting channel as input for the process implementing your task. Warning Chunks are kept in memory by default. When splitting big files, specify the parameter file: true to save the chunks into files. See the documentation for details. Splitter for specific file formats are available, e.g. splitFasta and splitFastq .","title":"Solution"},{"location":"process-per-file-chunk/#code","text":"params.infile = \"$baseDir/data/poem.txt\" params.size = 5 process foo { debug true input: file x script: \"\"\" rev $x | rev \"\"\" } workflow { Channel.fromPath(params.infile) \\ | splitText(by: params.size) \\ | foo }","title":"Code"},{"location":"process-per-file-chunk/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/process-per-file-chunk.nf","title":"Run it"},{"location":"process-per-file-output/","text":"Problem A task in your workflow produces two or more files at time. A downstream task needs to process each of these files independently. Solution Use the flatten operator to transform the outputs of the upstream process to a channel that emits each file separately. Then use this channel as input for the downstream process. Code process foo { output: path '*.txt' script: ''' echo Hello there! > file1.txt echo What a beautiful day > file2.txt echo I hope you are having fun! > file3.txt ''' } process bar { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { foo | flatten | bar } Run it Use the the following command to execute the example: nextflow run patterns/process-per-file-output.nf","title":"Process per file output"},{"location":"process-per-file-output/#problem","text":"A task in your workflow produces two or more files at time. A downstream task needs to process each of these files independently.","title":"Problem"},{"location":"process-per-file-output/#solution","text":"Use the flatten operator to transform the outputs of the upstream process to a channel that emits each file separately. Then use this channel as input for the downstream process.","title":"Solution"},{"location":"process-per-file-output/#code","text":"process foo { output: path '*.txt' script: ''' echo Hello there! > file1.txt echo What a beautiful day > file2.txt echo I hope you are having fun! > file3.txt ''' } process bar { debug true input: path x script: \"\"\" cat $x \"\"\" } workflow { foo | flatten | bar }","title":"Code"},{"location":"process-per-file-output/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/process-per-file-output.nf","title":"Run it"},{"location":"process-per-file-pairs/","text":"Problem You need to process the files in a directory, grouping them by pairs. Solution Use the Channel.fromFilePairs method to create a channel that emits file pairs matching a glob pattern. The pattern must match a common prefix in the paired file names. The matching files are emitted as tuples in which the first element is the grouping key of the matching files and the second element is the file pair itself. Code process foo { debug true input: tuple val(sampleId), file(reads) script: \"\"\" echo your_command --sample $sampleId --reads $reads \"\"\" } workflow { Channel.fromFilePairs(\"$baseDir/data/reads/*_{1,2}.fq.gz\", checkIfExists:true) \\ | foo } Run it nextflow run patterns/process-per-file-pairs.nf Custom grouping strategy When necessary, it is possible to define a custom grouping strategy. A common use case is for alignment BAM files ( sample1.bam ) that come along with their index file. The difficulty is that the index is sometimes called sample1.bai and sometimes sample1.bam.bai depending on the software used. The following example can accommodate both cases. process foo { debug true tag \"$sampleId\" input: tuple val(sampleId), file(bam) script: \"\"\" echo your_command --sample ${sampleId} --bam ${sampleId}.bam \"\"\" } workflow { Channel.fromFilePairs(\"$baseDir/data/alignment/*.{bam,bai}\", checkIfExists:true) { file -> file.name.replaceAll(/.bam|.bai$/,'') } \\ | foo } Run it nextflow run patterns/process-per-file-pairs-custom.nf","title":"Process per file pairs"},{"location":"process-per-file-pairs/#problem","text":"You need to process the files in a directory, grouping them by pairs.","title":"Problem"},{"location":"process-per-file-pairs/#solution","text":"Use the Channel.fromFilePairs method to create a channel that emits file pairs matching a glob pattern. The pattern must match a common prefix in the paired file names. The matching files are emitted as tuples in which the first element is the grouping key of the matching files and the second element is the file pair itself.","title":"Solution"},{"location":"process-per-file-pairs/#code","text":"process foo { debug true input: tuple val(sampleId), file(reads) script: \"\"\" echo your_command --sample $sampleId --reads $reads \"\"\" } workflow { Channel.fromFilePairs(\"$baseDir/data/reads/*_{1,2}.fq.gz\", checkIfExists:true) \\ | foo }","title":"Code"},{"location":"process-per-file-pairs/#run-it","text":"nextflow run patterns/process-per-file-pairs.nf","title":"Run it"},{"location":"process-per-file-pairs/#custom-grouping-strategy","text":"When necessary, it is possible to define a custom grouping strategy. A common use case is for alignment BAM files ( sample1.bam ) that come along with their index file. The difficulty is that the index is sometimes called sample1.bai and sometimes sample1.bam.bai depending on the software used. The following example can accommodate both cases. process foo { debug true tag \"$sampleId\" input: tuple val(sampleId), file(bam) script: \"\"\" echo your_command --sample ${sampleId} --bam ${sampleId}.bam \"\"\" } workflow { Channel.fromFilePairs(\"$baseDir/data/alignment/*.{bam,bai}\", checkIfExists:true) { file -> file.name.replaceAll(/.bam|.bai$/,'') } \\ | foo }","title":"Custom grouping strategy"},{"location":"process-per-file-pairs/#run-it_1","text":"nextflow run patterns/process-per-file-pairs-custom.nf","title":"Run it"},{"location":"process-per-file-path/","text":"Problem You need to execute a task for each file that matches a glob pattern. Solution Use the Channel.fromPath method to create a channel emitting all files matching the glob pattern. Then, use the channel as input of the process implementing your task. Code process foo { debug true input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { foo(\"$baseDir/data/reads/*_1.fq.gz\") } Run it Use the the following command to execute the example: nextflow run patterns/process-per-file-path.nf","title":"Process per file path"},{"location":"process-per-file-path/#problem","text":"You need to execute a task for each file that matches a glob pattern.","title":"Problem"},{"location":"process-per-file-path/#solution","text":"Use the Channel.fromPath method to create a channel emitting all files matching the glob pattern. Then, use the channel as input of the process implementing your task.","title":"Solution"},{"location":"process-per-file-path/#code","text":"process foo { debug true input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { foo(\"$baseDir/data/reads/*_1.fq.gz\") }","title":"Code"},{"location":"process-per-file-path/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/process-per-file-path.nf","title":"Run it"},{"location":"process-per-file-range/","text":"Problem You need to execute a task over two or more series of files having a common index range. Solution Use the from method to define the range over which to repeat the task execution, then chain it with the map operator to associate each index with the corresponding input files. Finally, use the resulting channel as input for the process. Code process foo { debug true tag \"$sampleId\" input: tuple val(sampleId), file(indels), file(snps) \"\"\" echo foo_command --this $indels --that $snps \"\"\" } workflow { Channel.from(1..23) \\ | map { chr -> [\"sample${chr}\", file(\"/some/path/foo.${chr}.indels.vcf\"), file(\"/other/path/foo.snvs.${chr}.vcf\")] } \\ | foo } Run it nextflow run patterns/process-per-file-range.nf","title":"Process per file range"},{"location":"process-per-file-range/#problem","text":"You need to execute a task over two or more series of files having a common index range.","title":"Problem"},{"location":"process-per-file-range/#solution","text":"Use the from method to define the range over which to repeat the task execution, then chain it with the map operator to associate each index with the corresponding input files. Finally, use the resulting channel as input for the process.","title":"Solution"},{"location":"process-per-file-range/#code","text":"process foo { debug true tag \"$sampleId\" input: tuple val(sampleId), file(indels), file(snps) \"\"\" echo foo_command --this $indels --that $snps \"\"\" } workflow { Channel.from(1..23) \\ | map { chr -> [\"sample${chr}\", file(\"/some/path/foo.${chr}.indels.vcf\"), file(\"/other/path/foo.snvs.${chr}.vcf\")] } \\ | foo }","title":"Code"},{"location":"process-per-file-range/#run-it","text":"nextflow run patterns/process-per-file-range.nf","title":"Run it"},{"location":"process-when-empty/","text":"Problem You need to execute a process if a channel is empty. Solution Use the ifEmpty operator to emit a marker value to trigger the execution of the process. Example params.inputs = '' process foo { debug true input: val x when: x ## 'EMPTY' script: ''' echo hello ''' } workflow { reads_ch = params.inputs ? Channel.fromPath(params.inputs, checkIfExists:true) : Channel.empty() reads_ch \\ | ifEmpty { 'EMPTY' } \\ | foo } Run it Use the following command to run the script with an empty channel: nextflow run patterns/process-when-empty.nf Use the following command to provide the same script some input files, which prevents the process from being executed: nextflow run patterns/process-when-empty.nf --inputs ../data/prots/ \\*","title":"Process when empty"},{"location":"process-when-empty/#problem","text":"You need to execute a process if a channel is empty.","title":"Problem"},{"location":"process-when-empty/#solution","text":"Use the ifEmpty operator to emit a marker value to trigger the execution of the process.","title":"Solution"},{"location":"process-when-empty/#example","text":"params.inputs = '' process foo { debug true input: val x when: x ## 'EMPTY' script: ''' echo hello ''' } workflow { reads_ch = params.inputs ? Channel.fromPath(params.inputs, checkIfExists:true) : Channel.empty() reads_ch \\ | ifEmpty { 'EMPTY' } \\ | foo }","title":"Example"},{"location":"process-when-empty/#run-it","text":"Use the following command to run the script with an empty channel: nextflow run patterns/process-when-empty.nf Use the following command to provide the same script some input files, which prevents the process from being executed: nextflow run patterns/process-when-empty.nf --inputs ../data/prots/ \\*","title":"Run it"},{"location":"publish-matching-glob/","text":"Problem A task in your workflow creates many output files that are required by a downstream task. You want to store some of those files into separate directories depending on the file name. Solution Use two or more publishDir directives to publish the output files into separate paths. For each directive specify a different glob pattern using the pattern option to store into each directory only the files that match the provided pattern. Code params.reads = \"$baseDir/data/reads/*_{1,2}.fq.gz\" params.outdir = 'my-results' process foo { publishDir \"$params.outdir/$sampleId/counts\", pattern: \"*_counts.txt\" publishDir \"$params.outdir/$sampleId/outlooks\", pattern: '*_outlook.txt' publishDir \"$params.outdir/$sampleId/\", pattern: '*.fq' input: tuple val(sampleId), file('sample1.fq.gz'), file('sample2.fq.gz') output: path \"*\" script: \"\"\" < sample1.fq.gz zcat > sample1.fq < sample2.fq.gz zcat > sample2.fq awk '{s++}END{print s/4}' sample1.fq > sample1_counts.txt awk '{s++}END{print s/4}' sample2.fq > sample2_counts.txt head -n 50 sample1.fq > sample1_outlook.txt head -n 50 sample2.fq > sample2_outlook.txt \"\"\" } workflow { Channel.fromFilePairs(params.reads, checkIfExists: true, flat: true) \\ | foo } Run it Run the script with the following command: nextflow run patterns/publish-matching-glob.nf","title":"Store outputs matching a glob pattern"},{"location":"publish-matching-glob/#problem","text":"A task in your workflow creates many output files that are required by a downstream task. You want to store some of those files into separate directories depending on the file name.","title":"Problem"},{"location":"publish-matching-glob/#solution","text":"Use two or more publishDir directives to publish the output files into separate paths. For each directive specify a different glob pattern using the pattern option to store into each directory only the files that match the provided pattern.","title":"Solution"},{"location":"publish-matching-glob/#code","text":"params.reads = \"$baseDir/data/reads/*_{1,2}.fq.gz\" params.outdir = 'my-results' process foo { publishDir \"$params.outdir/$sampleId/counts\", pattern: \"*_counts.txt\" publishDir \"$params.outdir/$sampleId/outlooks\", pattern: '*_outlook.txt' publishDir \"$params.outdir/$sampleId/\", pattern: '*.fq' input: tuple val(sampleId), file('sample1.fq.gz'), file('sample2.fq.gz') output: path \"*\" script: \"\"\" < sample1.fq.gz zcat > sample1.fq < sample2.fq.gz zcat > sample2.fq awk '{s++}END{print s/4}' sample1.fq > sample1_counts.txt awk '{s++}END{print s/4}' sample2.fq > sample2_counts.txt head -n 50 sample1.fq > sample1_outlook.txt head -n 50 sample2.fq > sample2_outlook.txt \"\"\" } workflow { Channel.fromFilePairs(params.reads, checkIfExists: true, flat: true) \\ | foo }","title":"Code"},{"location":"publish-matching-glob/#run-it","text":"Run the script with the following command: nextflow run patterns/publish-matching-glob.nf","title":"Run it"},{"location":"publish-process-outputs/","text":"Problem You need to store the outputs of one or more processes into a directory structure of your choice. Solution Use the publishDir directive to define a custom directory where the process outputs should be saved. Code params.reads = \"$baseDir/data/reads/*{1,2}.fq.gz\" params.outdir = 'my-results' process foo { publishDir \"$params.outdir/$sampleId\" input: tuple val(sampleId), file(samples) output: path '*.fq' script: \"\"\" < ${samples[0]} zcat > sample_1.fq < ${samples[1]} zcat > sample_2.fq \"\"\" } workflow { Channel.fromFilePairs(params.reads, checkIfExists: true) \\ | foo } Run it Run the script with the following command: nextflow run patterns/publish-process-outputs.nf","title":"Store process outputs"},{"location":"publish-process-outputs/#problem","text":"You need to store the outputs of one or more processes into a directory structure of your choice.","title":"Problem"},{"location":"publish-process-outputs/#solution","text":"Use the publishDir directive to define a custom directory where the process outputs should be saved.","title":"Solution"},{"location":"publish-process-outputs/#code","text":"params.reads = \"$baseDir/data/reads/*{1,2}.fq.gz\" params.outdir = 'my-results' process foo { publishDir \"$params.outdir/$sampleId\" input: tuple val(sampleId), file(samples) output: path '*.fq' script: \"\"\" < ${samples[0]} zcat > sample_1.fq < ${samples[1]} zcat > sample_2.fq \"\"\" } workflow { Channel.fromFilePairs(params.reads, checkIfExists: true) \\ | foo }","title":"Code"},{"location":"publish-process-outputs/#run-it","text":"Run the script with the following command: nextflow run patterns/publish-process-outputs.nf","title":"Run it"},{"location":"publish-rename-outputs/","text":"Problem You need to save the outputs of a process to a directory, giving each file a name of your choice. Solution The publishDir allows you to save the process outputs in a directory of your choice. Use the saveAs option to give each file a name of your choice, providing a custom rule as a closure . Code process foo { publishDir 'results', saveAs: { filename -> \"foo_$filename\" } output: path '*.txt' ''' touch this.txt touch that.txt ''' } workflow { foo() } Run it nextflow run patterns/publish-rename-outputs.nf Save outputs in a sub-directory The same pattern can be used to store specific files in separate directories depending on the actual name. process foo { publishDir 'results', saveAs: { filename -> filename.endsWith(\".zip\") ? \"zips/$filename\" : filename } output: path '*' ''' touch this.txt touch that.zip ''' } workflow { foo() } Tip Relative paths are resolved against the publishDir store path. Use an absolute path to store files in a directory outside the publishDir store path. Run it nextflow run patterns/publish-rename-outputs-subdirs.nf","title":"Store outputs renaming files"},{"location":"publish-rename-outputs/#problem","text":"You need to save the outputs of a process to a directory, giving each file a name of your choice.","title":"Problem"},{"location":"publish-rename-outputs/#solution","text":"The publishDir allows you to save the process outputs in a directory of your choice. Use the saveAs option to give each file a name of your choice, providing a custom rule as a closure .","title":"Solution"},{"location":"publish-rename-outputs/#code","text":"process foo { publishDir 'results', saveAs: { filename -> \"foo_$filename\" } output: path '*.txt' ''' touch this.txt touch that.txt ''' } workflow { foo() }","title":"Code"},{"location":"publish-rename-outputs/#run-it","text":"nextflow run patterns/publish-rename-outputs.nf","title":"Run it"},{"location":"publish-rename-outputs/#save-outputs-in-a-sub-directory","text":"The same pattern can be used to store specific files in separate directories depending on the actual name. process foo { publishDir 'results', saveAs: { filename -> filename.endsWith(\".zip\") ? \"zips/$filename\" : filename } output: path '*' ''' touch this.txt touch that.zip ''' } workflow { foo() } Tip Relative paths are resolved against the publishDir store path. Use an absolute path to store files in a directory outside the publishDir store path.","title":"Save outputs in a sub-directory"},{"location":"publish-rename-outputs/#run-it_1","text":"nextflow run patterns/publish-rename-outputs-subdirs.nf","title":"Run it"},{"location":"skip-process-execution/","text":"Problem You have two sequential tasks in your workflow. When an optional flag is specified, the first task should be skipped and its input(s) should be processed by the second task. Solution Use an empty channel, created in a conditional expression, to skip the first process execution when an optional parameter is specified. Then, define the second process input as a mix of the first process output (when executed) and the input channel. Code params.skip = false params.input = \"$baseDir/data/reads/sample.fq.gz\" process foo { input: path x output: file('*.fastq') script: \"\"\" < $x zcat > ${x.simpleName}.fastq \"\"\" } process bar { debug true input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { input_ch = Channel.fromPath(params.input) (foo_ch, bar_ch) = params.skip ? [Channel.empty(), input_ch] : [input_ch, Channel.empty()] foo_ch | foo | mix(bar_ch) | bar } Run it Use the the following command to execute the example: nextflow run patterns/skip-process-execution.nf The processes foo and bar are executed. Run the same command with the --skip command line option: nextflow run patterns/skip-process-execution.nf --skip This time only the bar process is executed.","title":"Skip process execution"},{"location":"skip-process-execution/#problem","text":"You have two sequential tasks in your workflow. When an optional flag is specified, the first task should be skipped and its input(s) should be processed by the second task.","title":"Problem"},{"location":"skip-process-execution/#solution","text":"Use an empty channel, created in a conditional expression, to skip the first process execution when an optional parameter is specified. Then, define the second process input as a mix of the first process output (when executed) and the input channel.","title":"Solution"},{"location":"skip-process-execution/#code","text":"params.skip = false params.input = \"$baseDir/data/reads/sample.fq.gz\" process foo { input: path x output: file('*.fastq') script: \"\"\" < $x zcat > ${x.simpleName}.fastq \"\"\" } process bar { debug true input: path x script: \"\"\" echo your_command --input $x \"\"\" } workflow { input_ch = Channel.fromPath(params.input) (foo_ch, bar_ch) = params.skip ? [Channel.empty(), input_ch] : [input_ch, Channel.empty()] foo_ch | foo | mix(bar_ch) | bar }","title":"Code"},{"location":"skip-process-execution/#run-it","text":"Use the the following command to execute the example: nextflow run patterns/skip-process-execution.nf The processes foo and bar are executed. Run the same command with the --skip command line option: nextflow run patterns/skip-process-execution.nf --skip This time only the bar process is executed.","title":"Run it"},{"location":"state-dependency/","text":"Problem You need to synchronize the execution of two processes for which there isn't a data dependency, so that process bar is executed after the completion of process foo . Solution Add an output channel to process foo that produces a ready signal. Then pass this channel as input to process bar in order to trigger its execution when foo completes. Code process foo { output: val true script: \"\"\" echo your_command_here \"\"\" } process bar { input: val ready path fq script: \"\"\" echo other_commad_here --reads $fq \"\"\" } workflow { reads_ch = Channel.fromPath(\"$baseDir/data/reads/11010*.fq.gz\", checkIfExists:true) foo() bar(foo.out, reads_ch) } Run it Run the example using this command: nextflow run patterns/state-dependency.nf","title":"State dependency"},{"location":"state-dependency/#problem","text":"You need to synchronize the execution of two processes for which there isn't a data dependency, so that process bar is executed after the completion of process foo .","title":"Problem"},{"location":"state-dependency/#solution","text":"Add an output channel to process foo that produces a ready signal. Then pass this channel as input to process bar in order to trigger its execution when foo completes.","title":"Solution"},{"location":"state-dependency/#code","text":"process foo { output: val true script: \"\"\" echo your_command_here \"\"\" } process bar { input: val ready path fq script: \"\"\" echo other_commad_here --reads $fq \"\"\" } workflow { reads_ch = Channel.fromPath(\"$baseDir/data/reads/11010*.fq.gz\", checkIfExists:true) foo() bar(foo.out, reads_ch) }","title":"Code"},{"location":"state-dependency/#run-it","text":"Run the example using this command: nextflow run patterns/state-dependency.nf","title":"Run it"}]}